---

layout: post
title: MVCC
category: 技术
tags: Storage
keywords: TIDB

---

## 前言


截止到2019.11.19，对mvcc 的理解仍然有很多黑洞，可能需要阅读源码才能解开。我们需要知道的是，基于一个全局自增id，事务在start时申请id 作为自己的标识，修改（删除也可视为修改）一条记录时 不改变原有记录并新增 一条带上事务id的记录 即可成功的将修改操作转换为新增操作，提交时


## mvcc 干啥的，同类的解决方案有哪些

多个并发执行体操作一个数据 会引起数据冲突，需要进行并发控制，并发控制有两个思路

1. 悲观机制，You can avoid them, by employing a pessimistic locking mechanism (e.g. Read/Write locks, Two-Phase Locking)
2. 乐观机制，You can allow conflicts to occur, but you need to detect them using an optimistic locking mechanism (e.g. logical clock, MVCC)


具体到数据库层面，追求绝对的并发安全会导致性能的下降。为了提高性能，可以降低并发控制”强度“，从读写的角度提出了一个隔离性的概念来描述并发安全的程度。 隔离性的要求不同，悲观 和乐观机制 可以调整内部细节 来达到不同的隔离性。

1. 悲观锁，以mysql innodb 为例[彻底理解事务的4个隔离级别](https://www.cnblogs.com/jycboy/p/transaction.html)

    ||读|写|
    |---|---|---|
    |Read uncommitted|事务在读数据的时候并未对数据加锁|事务在修改数据的时候只对数据增加`行级共享锁`|
    |Read committed|事务对当前被读取的数据加 `行级共享锁`（当读到时才加锁），<br>一旦读完该行，立即释放该行级共享锁|事务在更新某数据的瞬间（就是发生更新的瞬间），<br>必须先对其加 `行级排他锁`，直到事务结束才释放|
    |Repeatable read|事务在读取某数据的瞬间（就是开始读取的瞬间），必须先对其加 `行级共享锁`，直到事务结束才释放|事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加 `行级排他锁`，直到事务结束才释放|
    |Serializable|事务在读取数据时，必须先对其加 `表级共享锁` ，直到事务结束才释放|事务在更新数据时，必须先对其加 `表级排他锁` ，直到事务结束才释放|

    为了实现隔离性的效果，不仅用了锁， 加锁的时间、粒度和性质（共享or排他）也很讲究。

2. 乐观锁，MVCC 只是一个思想，并不是某个特定的实现。做到了读与读不冲突，读与写不冲突，但**写写还需要锁去控制冲突**。

多事务 对同一个数据记录 同时读写的准确性，`<read,read>``<write,write>` 一般都没疑问，主要说的是`<read,write>`，具体的说就是`<read,udpate>``<read,delete>`，再具体的说，是write 一方的update/delete 操作read 一方能不能看到、何时看到。

snapshot isolation [事务隔离级别SI到RC以及优化](http://www.zenlife.tk/si-rc.md)RR和SI是一个差不多强度的隔离级别，RR有幻读问题，SI没有；而SI有写偏问题，RR没有。它们都解决了读未提交，不可重复读，然后都有对方处理不了的异常，所以算是差不多强度。只不过当年定义隔离级别的ANSI标准的时候，大家思维还局限在基于锁的实现，所以标准定义不是很完美，定义了RU，RC，RR，Serializability，后来基于MVCC的实现流行之后，才有了SI。SI的实现，需要拿一次startTS和一次commitTS

## 各家实现mvcc的方式不一致

各家方案的共同点

1. 每一个record 有一个 唯一标识primary key 
2. 同一个record 存在多个版本，一个事务一个版本，多个版本的数据 可能是一个数据形态（postgresql），也可能是不同形态（mysql，老版本以undo log 形式存在）
3. 对于不同隔离级别，mvcc 处理机制不同。
4. mvcc 的工作基于 额外的数据结构 及 作用于之上的策略。

[PostgreSQL、Oracle/MySQL和SQL Server的MVCC实现原理方式](https://www.jdon.com/repository/database-mvcc.html)

## postgresql

While Oracle and MySQL use the undo log to capture uncommitted changes so that rows can be reconstructed to their previously committed version, PostgreSQL stores all row versions in the table data structure.

PostgreSQL 中的 MVCC 实现原理可简单概括如下（真的可以不用锁实现三种隔离性）

1. 数据文件中存放同一逻辑行的多个行版本（称为 Tuple ）
2. 每个行版本的头部记录创建以及删除该行版本的事务的 ID （分别称为 xmin 和 xmax ）
3. 每个事务的状态（运行中，中止或提交）记录在 pg_clog 文件中，所以能根据事务id 查询事务是否已提交
4. 根据上面的数据并运用一定的规则每个事务只会看到一个特定的行版本

    1. 未提交读和提交读实际上都被实现为提交读
    2. Read committed, 只读取已经提交事务的结果 [SQL优化（六） MVCC PostgreSQL实现事务和多版本并发控制的精华](http://www.jasongj.com/sql/mvcc/)
    3. Repeatable read, 只读取xmin小于当前事务ID且已提交的事务的Tuple。postgresql RR隔离级别不允许幻读


[How does MVCC (Multi-Version Concurrency Control) work](https://vladmihalcea.com/how-does-mvcc-multi-version-concurrency-control-work/)

Transaction Id is a 32-bit integer, when connection start a new transaction, and we can see their transaction ids by calling the txid_current() PostgreSQL function.

一个update a record 为例，在Read committed 时

![](/public/upload/storage/postgresql_mvcc.png)

1. Both Alice and Bob start a new transaction, and we can see their transaction ids by calling the txid_current() PostgreSQL function
2. When Bob updates a post record, we can see two operations happening: a DELETE and an INSERT.
The previous row version is marked as deleted by setting the t_max  column value to Bob’s transaction id(用xmax>0来标识该`<row，version>`元组被删除), and a new row version is created which has the t_min column value set to Bob’s transaction id
3. Under default Read Committed isolation level, until Bob manages to commit his transaction, Alice can still see the previous record version. 
4. After Bob has committed, Alice can now see the new row version that was updated by Bob

|ACID|实现技术|
|---|---|
|原子性（Atomicity）|MVCC|
|一致性（Consistency）|约束（主键、外键等）|
|隔离性|MVCC|
|持久性|WAL|

对于插入操作，PostgreSQL会将当前事务ID存于xmin中。对于删除操作，其事务ID会存于xmax中。对于更新操作，PostgreSQL会将当前事务ID存于旧数据的xmax中，并存于新数据的xin中。换句话说，事务对增、删和改所操作的数据上都留有其事务ID，可以很方便的提交该批操作或者完全撤销操作，从而实现了事务的原子性。

MVCC 的实现让我想起了 基于区块链的比特币，区块链的比特币从来没有一个余额存在，余额是根据历史的交易记录累计算出来的。PostgreSQL 的数据会有大量的Tuple 存在（当然会有一个gc 机制去清理Tuple），不同的事务 按规则读取自己可见的Tuple。

## mysql

[MVCC机制](https://my.oschina.net/u/3942910/blog/1928981)

InnoDB为每行记录都实现了三个隐藏字段：6字节的事务ID（DB_TRX_ID ）；7字节的回滚指针（DB_ROLL_PTR）；隐藏的ID。

[InnoDB MVCC RR隔离级别下的数据可见性总结](https://www.cnblogs.com/itZhy/p/8831947.html)

![](/public/upload/storage/innodb_mvcc.png)

innodb 中注意的一个点：事务ID并非在事务begin时就分配，而是在事务首次执行非快照读操作（SELECT ... FOR UPDATE/IN SHARE MODE、UPDATE、DELETE）时分配。

## tidb

tidb mvcc 机制一个难点是 其mvcc 既实现了多版本（解决多个事务同时读写一个key的问题），也实现了分布式事务（一个是事务中涉及多个key，每个key在不同的region/机器上，所以要保证多个key同时修改成功或失败）。



|ACID|实现技术|
|---|---|
|原子性|两阶段提交时，通过 `primary key` 保证原子性。 `primary key` commit 成功与否决定事务成功与否|
|一致性||
|隔离性|通过MVCC，保证隔离级别为  Repeatable Read（也有一说是SI）|
|持久性|tikv 保证持久化，多副本|


### 分布式事务

[TiKV 事务模型概览，Google Spanner 开源实现](https://pingcap.com/blog-cn/tidb-transaction-model/)其实本质上来说，在一个分布式系统中实现跨节点事务，**只有两阶段提交一种办法**（3PC 本质上也是 2PC 的一个优化），一般都会有一个中央节点作为事务管理器。TiDB 的事务模型参考了 Percolator 论文，Percolator仅仅依靠**客户端侧**的协议和一个全局的授时服务器TSO就实现了跨机器的多行事务。Percolator 的模型通过对于锁的优化，去掉了单点的事务管理器的概念，将整个事务模型中的单点局限于授时服务器上。

### 对分布式事务的猜测

![](/public/upload/storage/precolator.png)

假设分布式kv 不支持ts，想原子修改k1和k2，直接修改

1. set k1 成功
2. set k2 失败
3. 此时应该回滚，set k1 到原来的值，但这个时候 kv client 挂了呢，k1,k2就永远不一致了

**一次提交只能对原始数据修改，中途宕机没办法callbak**，所以一个直观的想法就是， 每次update k1 ，k1 原来的值还在，另外创建一个新k1 row，于是key 便有了版本的概念。为防止版本号冲突，版本使用全局唯一id/时间戳来表示。key 有了多个版本，如何认定哪个版本有效呢？将存储分为两份 default store 和 commit store，在commit store 里对 k1 的version 进行确认。**于是数据有两个版本，有两次提交**。重新走下流程：


1. 假设k1已有版本是ts1，add k1_ts2
2. 假设k2已有版本是ts1，add k2_ts2 ，但add 失败
3. 此时应该回滚， 因为没有 对k1_ts2 进行确认，所以k1_ts2 不是有效数据，所谓的callback 什么都不做即可。
4. 假设k2已有版本是ts1，add k2_ts2 成功， 则commit store中 add `<k1_ts3,ts2>` 和 `<k2_ts3,ts2>`进行确认

此处有一个问题，如何判断事务完成（成功失败都叫完成）？default store 存储了暂存的或有效的key，commit key 只是标记default store中哪些key 有效，却无法标记事务是否提交。 对于一个事务的读操作来说，假设新的事务只读取k2，**它如何知道k2 在不在一个事务里**，只有知道另一个事务是否commit，自己才可以根据隔离性要求 决定 read commit 还是read uncommitted。

此外，两个写写 事务 也还是需要加锁 才可以防止写冲突（mvcc 解决写冲突也是靠锁的）

所以，事务开启之前，要先尝试 对k1和k2 加锁，当然在kv store上只能是逻辑锁，除default store 和 commit store之外再加一个lock store。事务关闭后，移除k1和k2锁。 lock  可以防止写写冲突，恰好因为事务开启和关闭会create和remove 逻辑lock，**lock 存在与否 顺带也表示了事务处于commting 状态**。 读操作 可以根据 是否check 这个lock 来支持隔离性强度。

加锁方式优化；[TiDB 新特性漫谈：悲观事务](https://pingcap.com/blog-cn/pessimistic-transaction-the-new-features-of-tidb/)标准的 Percolator 模型采用的是乐观事务模型，在提交之前，会收集所有参与修改的行（key-value pairs），从里面随机选一行，作为这个事务的 Primary row，剩下的行自动作为 secondary rows，这里注意，primary 是随机的，具体是哪行完全不重要，primary 的唯一意义就是负责标记这个事务的完成状态（secondary rows 的commit 和 remove lock 可以异步执行，这样事务可以尽早提前结束）。


[Google Percolator 的事务模型](https://github.com/ngaut/builddatabase/blob/master/percolator/README.md)一系列文档只是阐述了 how，但没说为什么可以，留待以后研究吧。

整体上思索几个问题

1. 如何实现原子性

    1. RocksDB’s atomic write batch and TiKV’s transaction scheduler make it atomic to read and write a single user key
    2. different CFs in the same RocksDB instance uses a common WAL, providing the ability to write to different CFs atomically.
    3. Two-phase commit (2PC) protocol.  commit primary key + remove primary lock  成功即认为事务提交成功，否则即事务提交失败。但commit primary key + remove primary lock 两条指令如何原子写入还有待研究。
2. 如何实现一致性
3. 如何实现隔离性
4. 如何实现持久性

### MVCC

MVCC层暴露给上层的接口行为定义：

    MVCCGet(key, version), 返回某 key 小于等于 version 的最大版本的值
    MVCCScan(startKey, endKey, limit, version), 返回 [startKey, endKey) 区间内的 key 小于等于 version 的最大版本的键和值，上限 limit 个
    MVCCPut(key, value, version) 插入某个键值对，如果 version 已经存在，则覆盖它。上层事务系统有责任维护自增version来避免read-modify-write
    MVCCDelete(key, version) 删除某个特定版本的键值对, 这个需要与上层的事务删除接口区分，只有 GC 模块可以调用这个接口


## 编程语言中的并发安全控制

[从CPU Cache出发彻底弄懂volatile/synchronized/cas机制](https://juejin.im/post/5c6b99e66fb9a049d51a1094)

cpu 硬件因为多级缓存的缘故，一般的cpu 指令操作的是local cache，对于同一个数据，因为local cache 存在天然的有了多 verison。

各CPU都会通过总线嗅探来监视其他CPU，一旦某个CPU对自己Cache中缓存的共享变量做了修改（能做修改的前提是共享变量所在的缓存行的状态不是无效的），那么就会导致其他缓存了该共享变量的CPU将该变量所在的Cache Line置为无效状态，在下次CPU访问无效状态的缓存行时会首先要求对共享变量做了修改的CPU将修改从Cache写回主存，然后自己再从主存中将最新的共享变量读到自己的缓存行中。

**缓存一致性协议**通过缓存锁定来保证CPU修改缓存行中的共享变量并通知其他CPU将对应缓存行置为无效这一操作的原子性，即当某个CPU修改位于自己缓存中的共享变量时会禁止其他也缓存了该共享变量的CPU访问自己缓存中的对应缓存行，并在缓存锁定结束前通知这些CPU将对应缓存行置为无效状态。在缓存锁定出现之前，是通过总线锁定来实现CPU之间的同步的，即CPU在回写主存时会锁定总线不让其他CPU访问主存，但是这种机制开销较大

